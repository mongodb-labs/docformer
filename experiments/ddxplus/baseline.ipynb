{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fb0cddd6a59264",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from axon.gpt.data import load_df_from_mongodb\n",
    "from axon.utils.guild import load_secrets, print_guild_scalars\n",
    "from utils import get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf864690a3f51d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model_name='LogisticRegression', limit=20000, n_random_seeds=5\n"
     ]
    }
   ],
   "source": [
    "# experiment flags\n",
    "model_name = \"LogisticRegression\"  # \"XGBoost\" # \"RandomForest\"\n",
    "limit = 1000\n",
    "n_random_seeds = 5\n",
    "\n",
    "print(f\"Running {model_name=}, {limit=}, {n_random_seeds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2827794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaul model hyper parameters\n",
    "\n",
    "# logistic regression\n",
    "lr_C = 1.0\n",
    "lr_penalty = \"none\"\n",
    "lr_max_iter = 50\n",
    "lr_fit_intercept = True\n",
    "\n",
    "# xgboost\n",
    "xgb_learning_rate = 0.1\n",
    "xgb_max_depth = 5\n",
    "xgb_subsample = 1.0\n",
    "xgb_colsample_bytree = 1.0\n",
    "xgb_colsample_bylevel = 1.0\n",
    "xgb_min_child_weight = 1.0\n",
    "xgb_reg_alpha = 0.0\n",
    "xgb_reg_lambda = 1.0\n",
    "xgb_gamma = 0\n",
    "xgb_n_estimators = 100\n",
    "\n",
    "# random forest\n",
    "rf_n_estimators = 100\n",
    "rf_max_features = \"none\"\n",
    "rf_max_depth = \"none\"\n",
    "rf_min_samples_split = 5\n",
    "\n",
    "# lightgbm\n",
    "lgb_num_leaves = 10\n",
    "lgb_max_depth = 5\n",
    "lgb_learning_rate = 0.1\n",
    "lgb_n_estimators = 100\n",
    "lgb_min_child_weight = 1.0\n",
    "lgb_subsample = 0.8\n",
    "lgb_colsample_bytree = 0.8\n",
    "lgb_reg_alpha = 0.0\n",
    "lgb_reg_lambda = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca4fafa10c64b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading local secrets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "secrets = load_secrets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b137e20",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55de59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTION = {\"_id\": 0, \"DIFFERENTIAL_DIAGNOSIS\": 0}\n",
    "TARGET_FIELD = \"DIFFERENTIAL_DIAGNOSIS_NOPROB\"\n",
    "\n",
    "\n",
    "def load_docs(collection_name):\n",
    "    return load_df_from_mongodb(\n",
    "        uri=secrets[\"MONGO_URI\"],\n",
    "        db=secrets[\"DATABASE\"],\n",
    "        coll=collection_name,\n",
    "        projection=PROJECTION,\n",
    "        sort=[(\"_id\", 1)],\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_dataset(df):\n",
    "    # pull up relevant fields at the top of the df\n",
    "    df[\"EVIDENCES\"] = df[\"docs\"].apply(lambda x: x[\"EVIDENCES\"])\n",
    "    df[\"DIFFERENTIAL_DIAGNOSIS_NOPROB\"] = df[\"docs\"].apply(lambda x: x[\"DIFFERENTIAL_DIAGNOSIS_NOPROB\"])\n",
    "    df[\"PATHOLOGY\"] = df[\"docs\"].apply(lambda x: x[\"PATHOLOGY\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b0a33a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "train_docs_df = load_docs(collection_name=\"train-noprob\").pipe(preprocess_dataset)\n",
    "test_docs_df = load_docs(collection_name=\"test-noprob\").pipe(preprocess_dataset)\n",
    "val_docs_df = load_docs(collection_name=\"validate-noprob\").pipe(preprocess_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0958ddb",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e6d5e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(model_name, seed):\n",
    "    match model_name:\n",
    "        case \"LogisticRegression\":\n",
    "            clf = LogisticRegression(\n",
    "                random_state=seed,\n",
    "                C=lr_C if lr_penalty != \"none\" else 1.0,\n",
    "                penalty=lr_penalty if lr_penalty != \"none\" else None,\n",
    "                max_iter=lr_max_iter,\n",
    "                fit_intercept=True if lr_fit_intercept == 1 else False,\n",
    "                solver=\"saga\"\n",
    "            )\n",
    "        case \"XGBoost\":\n",
    "            clf = XGBClassifier(\n",
    "                random_state=seed,\n",
    "                max_depth=xgb_max_depth,\n",
    "                learning_rate=xgb_learning_rate,\n",
    "                n_estimators=xgb_n_estimators,\n",
    "                subsample=xgb_subsample,\n",
    "                colsample_bytree=xgb_colsample_bytree,\n",
    "                colsample_bylevel=xgb_colsample_bylevel,\n",
    "                min_child_weight=xgb_min_child_weight,\n",
    "                reg_alpha=xgb_reg_alpha,\n",
    "                reg_lambda=xgb_reg_lambda,\n",
    "                gamma=xgb_gamma,\n",
    "            )\n",
    "        case \"RandomForest\":\n",
    "            clf = RandomForestClassifier(\n",
    "                random_state=seed,\n",
    "                n_estimators=rf_n_estimators,\n",
    "                max_features=rf_max_features if rf_max_features != \"none\" else None,\n",
    "                max_depth=rf_max_depth if rf_max_depth != \"none\" else None,\n",
    "                min_samples_split=rf_min_samples_split\n",
    "            )\n",
    "        case \"LightGBM\":\n",
    "            clf = LGBMClassifier(\n",
    "                random_state=seed,\n",
    "                verbose=-1,\n",
    "                num_leaves=lgb_num_leaves,\n",
    "                max_depth=lgb_max_depth,\n",
    "                learning_rate=lgb_learning_rate,\n",
    "                n_estimators=lgb_n_estimators,\n",
    "                min_child_weight=lgb_min_child_weight,\n",
    "                subsample=lgb_subsample,\n",
    "                colsample_bytree=lgb_colsample_bytree,\n",
    "                reg_alpha=lgb_reg_alpha,\n",
    "                reg_lambda=lgb_reg_lambda,\n",
    "            )\n",
    "\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown model {model_name}\")\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "98bd9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RobinVujanic\\venvs\\axon\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['E_152_@_V_132', 'E_55_@_V_136', 'E_55_@_V_178'] will be ignored\n",
      "  warnings.warn(\n",
      "C:\\Users\\RobinVujanic\\venvs\\axon\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['E_133_@_V_162', 'E_55_@_V_136', 'E_55_@_V_178', 'E_55_@_V_45'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# encode data\n",
    "mlb_ddx = MultiLabelBinarizer()\n",
    "mlb_evd = MultiLabelBinarizer()\n",
    "\n",
    "# train\n",
    "X_train = mlb_evd.fit_transform(train_docs_df[\"EVIDENCES\"])\n",
    "y_train = mlb_ddx.fit_transform(train_docs_df[\"DIFFERENTIAL_DIAGNOSIS_NOPROB\"])\n",
    "\n",
    "# val\n",
    "X_val = mlb_evd.transform(val_docs_df[\"EVIDENCES\"])\n",
    "y_val = mlb_ddx.transform(val_docs_df[\"DIFFERENTIAL_DIAGNOSIS_NOPROB\"])\n",
    "y_pathology_val = mlb_ddx.transform(val_docs_df[\"PATHOLOGY\"].apply(lambda x: [x, ]))\n",
    "y_pathology_val = np.where(y_pathology_val > 0.5)[1]\n",
    "\n",
    "# test\n",
    "X_test = mlb_evd.transform(test_docs_df[\"EVIDENCES\"])\n",
    "y_test = mlb_ddx.transform(test_docs_df[\"DIFFERENTIAL_DIAGNOSIS_NOPROB\"])\n",
    "y_pathology_test = mlb_ddx.transform(test_docs_df[\"PATHOLOGY\"].apply(lambda x: [x, ]))\n",
    "y_pathology_test = np.where(y_pathology_test > 0.5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "242ff782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test[:3,:], y_test[:3,:], y_pathology_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d46e57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a152877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression(max_iter=10, penalty='l1', random_state=0,\n",
      "                   solver='liblinear')\n",
      "|  step: 0  |  recall_val: 0.9004263372938938  |  precision_val: 0.8870666039515851  |  f1_val: 0.8936965452577607  |  gtpa_val: 0.99585  |  gtpa_at_1_val: 0.69515  |  recall_test: 0.9008239804993183  |  precision_test: 0.8882346888419146  |  f1_test: 0.8944850403534006  |  gtpa_test: 0.9952  |  gtpa_at_1_test: 0.69995  |\n",
      "Training LogisticRegression(max_iter=10, penalty='l1', random_state=1,\n",
      "                   solver='liblinear')\n",
      "|  step: 1  |  recall_val: 0.9006822054160886  |  precision_val: 0.8869225825533802  |  f1_val: 0.8937494384258217  |  gtpa_val: 0.99585  |  gtpa_at_1_val: 0.6902  |  recall_test: 0.9011261178939474  |  precision_test: 0.8880576288652519  |  f1_test: 0.8945441461951216  |  gtpa_test: 0.9953  |  gtpa_at_1_test: 0.6949  |\n",
      "Training LogisticRegression(max_iter=10, penalty='l1', random_state=2,\n",
      "                   solver='liblinear')\n",
      "|  step: 2  |  recall_val: 0.9007511141601579  |  precision_val: 0.8871587858311466  |  f1_val: 0.8939032831332995  |  gtpa_val: 0.99595  |  gtpa_at_1_val: 0.6956  |  recall_test: 0.9011501989082487  |  precision_test: 0.8884827213705088  |  f1_test: 0.8947716283234932  |  gtpa_test: 0.9953  |  gtpa_at_1_test: 0.69845  |\n",
      "Training LogisticRegression(max_iter=10, penalty='l1', random_state=3,\n",
      "                   solver='liblinear')\n",
      "|  step: 3  |  recall_val: 0.9000891652192525  |  precision_val: 0.8869543302750852  |  f1_val: 0.8934734769889457  |  gtpa_val: 0.99595  |  gtpa_at_1_val: 0.68845  |  recall_test: 0.9007773470981861  |  precision_test: 0.8884049064098483  |  f1_test: 0.8945483481918315  |  gtpa_test: 0.9953  |  gtpa_at_1_test: 0.6939  |\n",
      "Training LogisticRegression(max_iter=10, penalty='l1', random_state=4,\n",
      "                   solver='liblinear')\n",
      "|  step: 4  |  recall_val: 0.9006251930612028  |  precision_val: 0.8868180759803402  |  f1_val: 0.8936683079382203  |  gtpa_val: 0.9959  |  gtpa_at_1_val: 0.6902  |  recall_test: 0.9010830305397445  |  precision_test: 0.8886362504525425  |  f1_test: 0.8948163593133946  |  gtpa_test: 0.9954  |  gtpa_at_1_test: 0.69505  |\n",
      "CPU times: total: 18.2 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "for clf_seed in range(n_random_seeds):\n",
    "    clf = get_classifier(model_name=model_name, seed=clf_seed)\n",
    "    multi_output_clf = MultiOutputClassifier(clf, n_jobs=4)\n",
    "    print(f'Training {clf}')\n",
    "\n",
    "    # train\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "        multi_output_clf.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate dev\n",
    "    y_pred_val = multi_output_clf.predict_proba(X_val)\n",
    "    y_pred_val = np.hstack([y_pred_val_i[:, 1].reshape(-1, 1) for y_pred_val_i in y_pred_val])\n",
    "\n",
    "    scores_val = get_scores(y_target=y_val, y_pred=y_pred_val, y_pathology=y_pathology_val, postfix=\"_val\")\n",
    "    for score_name, score in scores_val.items():\n",
    "        results[score_name].append(score)\n",
    "\n",
    "    # evaluate test\n",
    "    y_pred_test = multi_output_clf.predict_proba(X_test)\n",
    "    y_pred_test = np.hstack([y_pred_test_i[:, 1].reshape(-1, 1) for y_pred_test_i in y_pred_test])\n",
    "\n",
    "    scores_test = get_scores(y_target=y_test, y_pred=y_pred_test, y_pathology=y_pathology_test, postfix=\"_test\")\n",
    "    for score_name, score in scores_test.items():\n",
    "        results[score_name].append(score)\n",
    "\n",
    "    guild_output = {\"step\": clf_seed} | scores_val | scores_test\n",
    "    print_guild_scalars(**guild_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Individual fold metrics:')\n",
    "# print_guild_scalars(**results['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f81a21f74ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aggregated metrics:\")\n",
    "keys = list(results.keys())\n",
    "scalars = {}\n",
    "for key in keys:\n",
    "    scalars[f\"{key}_mean\"] = np.mean(results[key])\n",
    "    scalars[f\"{key}_std\"] = np.std(results[key])\n",
    "    scalars[f\"{key}_min\"] = np.min(results[key])\n",
    "    scalars[f\"{key}_max\"] = np.max(results[key])\n",
    "\n",
    "# print rounded scalars\n",
    "print_guild_scalars(**{k: f\"{v:.4f}\" for k, v in scalars.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb191c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
