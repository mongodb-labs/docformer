{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an ORiGAMi model on the Dungeons dataset\n",
    "\n",
    "### The Dungeons Dataset\n",
    "\n",
    "The Dungeons dataset is a (dungeons-themed) challenging synthetic dataset for supervised classification on \n",
    "semi-structured data. \n",
    "\n",
    "Each instance constains a corridor array with several rooms. Each room has a door number and contains multiple \n",
    "treasure chests with different-colored keys. All but one of the treasures are fake though.\n",
    "\n",
    "The goal is to find the correct room number and key color in each dungeon based on some clues and return the \n",
    "only real treasure. The clues are given at the top-level of the object in the fields `door` and `key_color`. \n",
    "\n",
    "To make it even harder, the `corridor` array may be shuffled (`shuffle_rooms=True`), and room objects may \n",
    "have a number of monsters as their first field (`with_monsters=True`), shifting the token positions of the \n",
    "serialized object by a variable amount. \n",
    "\n",
    "The following dictionary represents one example JSON instance:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"door\": 1,                              // clue which door is the correct one\n",
    "    \"key_color\": \"blue\",                    // clue which key is the correct one\n",
    "    \"corridor\": [                           // a corridor with many doors\n",
    "        {\n",
    "            \"monsters\": [\"troll\", \"wolf\"],  // optional monsters in front of the door\n",
    "            \"door_no\": 1,                   // door number in the corridor\n",
    "            \"red_key\": \"gemstones\",         // different keys return different treasures,\n",
    "            \"blue_key\": \"spellbooks\",       // but only one is real, the others are fake\n",
    "            \"green_key\": \"artifacts\"\n",
    "        },\n",
    "        {                                   // another room, here without monsters\n",
    "            \"door_no\": 0,                   // rooms can be shuffled, here room 0 comes after 1        \n",
    "            \"red_key\": \"diamonds\",          \n",
    "            \"blue_key\": \"gold\",           \n",
    "            \"green_key\": \"gemstones\"\n",
    "        },\n",
    "        // ... more rooms ...\n",
    "    ],\n",
    "    \"treasure\": \"spellbooks\"                // correct treasure (target label)\n",
    "}\n",
    "```\n",
    "\n",
    "The correct answer for this instance is \"spellbooks\", because the `door` is 1 and the `key_color` is \"blue\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The JSON objects are tokenized by recursively walking through them depth-first and extracting key and value tokens. \n",
    "Additionally, when encountering arrays or nested objects, special grammar tokens are included in the sequence. \n",
    "This diagram illustrates tokenization.\n",
    "\n",
    "<img src=\"../assets/preprocessing-diagram.png\" width=\"600px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from origami.utils import set_seed\n",
    "from origami.datasets.dungeons import generate_data\n",
    "from origami.preprocessing import (\n",
    "    DocTokenizerPipe,\n",
    "    PadTruncTokensPipe,\n",
    "    SchemaParserPipe,\n",
    "    TargetFieldPipe,\n",
    "    TokenEncoderPipe,\n",
    "    docs_to_df,\n",
    ")\n",
    "\n",
    "# for reproducibility\n",
    "# set_seed(123)\n",
    "\n",
    "# generate Dungeons dataset (see origami/datasets/dungeons.py)\n",
    "data = generate_data(\n",
    "    num_instances=100_000,\n",
    "    num_doors_range=(5, 10),\n",
    "    num_colors=3,\n",
    "    num_treasures=5,\n",
    "    with_monsters=True,    # makes it harder as token positions get shifted by variable amount\n",
    "    shuffle_rooms=True     # makes it harder because rooms are in random order\n",
    ")\n",
    "\n",
    "# print example dictionary\n",
    "print(json.dumps(data[0], indent=2))\n",
    "\n",
    "# load data into dataframe and split into train/test\n",
    "df = docs_to_df(data)\n",
    "train_docs_df, test_docs_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "TARGET_FIELD = \"treasure\"\n",
    "\n",
    "# create train and test pipelines\n",
    "pipes = {\n",
    "    \"schema\": SchemaParserPipe(),\n",
    "    \"target\": TargetFieldPipe(TARGET_FIELD),\n",
    "    \"tokenizer\": DocTokenizerPipe(path_in_field_tokens=True),\n",
    "    \"padding\": PadTruncTokensPipe(length=\"max\"),\n",
    "    \"encoder\": TokenEncoderPipe(),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([(name, pipes[name]) for name in (\"schema\", \"target\", \"tokenizer\", \"padding\", \"encoder\")])\n",
    "\n",
    "# process train, eval and test data\n",
    "train_df = pipeline.fit_transform(train_docs_df)\n",
    "test_df = pipeline.transform(test_docs_df)\n",
    "\n",
    "# get stateful objects\n",
    "schema = pipes[\"schema\"].schema\n",
    "encoder = pipes[\"encoder\"].encoder\n",
    "block_size = pipes[\"padding\"].length\n",
    "\n",
    "# print data stats\n",
    "print(f\"len train: {len(train_df)}, len test: {len(test_df)}\")\n",
    "print(f\"vocab size {encoder.vocab_size}\")\n",
    "print(f\"block size {block_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORiGAMi Model\n",
    "\n",
    "Here we instantiate an ORiGAMi model, a modified transformer trained on the token sequences created above.\n",
    "We use a standard \"medium\" configuration. ORiGAMi models are relatively robust to the choice of hyper-parameter\n",
    "and default configurations often work well for mid-sized datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from origami.model import ORIGAMI\n",
    "from origami.model.vpda import ObjectVPDA\n",
    "from origami.preprocessing import DFDataset\n",
    "from origami.utils import ModelConfig, TrainConfig, count_parameters\n",
    "\n",
    "# model and train configs\n",
    "model_config = ModelConfig.from_preset(\"medium\")   # see origami/utils/config.py for different presets\n",
    "model_config.vocab_size = encoder.vocab_size\n",
    "model_config.block_size = block_size\n",
    "\n",
    "train_config = TrainConfig()\n",
    "train_config.learning_rate = 1e-3\n",
    "train_config.print_every = 10\n",
    "train_config.eval_every = 500\n",
    "\n",
    "# wrap dataframes in datasets\n",
    "train_dataset = DFDataset(train_df)\n",
    "test_dataset = DFDataset(test_df)\n",
    "\n",
    "# create PDA and pass it to the model \n",
    "vpda = ObjectVPDA(encoder, schema)\n",
    "model = ORIGAMI(model_config, train_config, vpda=vpda)\n",
    "\n",
    "n_params = count_parameters(model)\n",
    "print(f\"Number of parameters: {n_params/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from origami.inference import Predictor\n",
    "from origami.utils import make_progress_callback\n",
    "\n",
    "# create a predictor\n",
    "predictor = Predictor(model, encoder, TARGET_FIELD)\n",
    "\n",
    "# create and register progress callback\n",
    "progress_callback = make_progress_callback(\n",
    "    train_config, train_dataset=train_dataset, test_dataset=test_dataset, predictor=predictor\n",
    ")\n",
    "model.set_callback(\"on_batch_end\", progress_callback)\n",
    "\n",
    "# train model (train and test accuracy should start to go towards 1.0 after ~3000 batches as loss drops below 0.7)\n",
    "model.train_model(train_dataset, batches=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test accuracy\n",
    "acc = predictor.accuracy(test_dataset, show_progress=True)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "# we can also access the predictions with the `predict()` method\n",
    "predictions = predictor.predict(test_dataset)\n",
    "print(\"Model predictions: \", predictions[:10])\n",
    "print(\"Correct labels: \", test_dataset.df[\"target\"].to_list()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
