{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a RandomForestClassifier on the Dungeons dataset\n",
    "\n",
    "### The Dungeons Dataset\n",
    "\n",
    "The Dungeons dataset is a (dungeons-themed) challenging synthetic dataset for supervised classification on\n",
    "semi-structured data.\n",
    "\n",
    "Each instance constains a corridor array with several rooms. Each room has a door number and contains multiple\n",
    "treasure chests with different-colored keys. All but one of the treasures are fake though.\n",
    "\n",
    "The goal is to find the correct room number and key color in each dungeon based on some clues and return the\n",
    "only real treasure. The clues are given at the top-level of the object in the fields `door` and `key_color`.\n",
    "\n",
    "To make it even harder, the `corridor` array may be shuffled (`shuffle_rooms=True`), and room objects may\n",
    "have a number of monsters as their first field (`with_monsters=True`), shifting the token positions of the\n",
    "serialized object by a variable amount.\n",
    "\n",
    "The following dictionary represents one example JSON instance:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"door\": 1, // clue which door is the correct one\n",
    "  \"key_color\": \"blue\", // clue which key is the correct one\n",
    "  \"corridor\": [\n",
    "    {\n",
    "      \"monsters\": [\"troll\", \"wolf\"], // optional monsters in front of the door\n",
    "      \"door_no\": 1, // door number in the corridor\n",
    "      \"red_key\": \"gemstones\", // different keys return different treasures,\n",
    "      \"blue_key\": \"spellbooks\", // but only one is real, the others are fake\n",
    "      \"green_key\": \"artifacts\"\n",
    "    },\n",
    "    {\n",
    "      // another room\n",
    "      \"door_no\": 0, // rooms can be shuffled, here room 0 comes after 1\n",
    "      \"red_key\": \"diamonds\",\n",
    "      \"blue_key\": \"gold\",\n",
    "      \"green_key\": \"gemstones\"\n",
    "    }\n",
    "    // ... more doors ...\n",
    "  ],\n",
    "  \"treasure\": \"spellbooks\" // correct treasure (target label)\n",
    "}\n",
    "```\n",
    "\n",
    "The correct answer for this instance is \"spellbooks\", because the `door` is 1 and the `key_color` is \"blue\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from origami.datasets.dungeons import generate_data\n",
    "from origami.utils import flatten_docs\n",
    "\n",
    "# generate Dungeons dataset (see origami/datasets/dungeons.py)\n",
    "data = generate_data(\n",
    "    num_instances=10_000,\n",
    "    num_doors_range=(5, 10),\n",
    "    num_colors=3,\n",
    "    num_treasures=5,\n",
    "    with_monsters=True,  # makes it harder as token positions get shifted by variable amount\n",
    "    shuffle_rooms=True,  # makes it harder because rooms are in random order\n",
    ")\n",
    "\n",
    "# flatten docs, load into dataframe and split into train/test\n",
    "df = pd.DataFrame(flatten_docs(data))\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "TARGET_FIELD = \"treasure\"\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "We will attempt to learn the same Dungeons dataset as used in `example_origami_dungeons.ipynb` with a\n",
    "[RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "from scikit-learn.\n",
    "\n",
    "We recursively flatten the dataset, creating a column for each field path (e.g. `corridor.2.blue_key`). The we\n",
    "transform all features through one-hot encoding, including the numeric fields (`door` and `door_no`) as these are\n",
    "of low cardinality (here max. 10) and better treated as categorical data.\n",
    "\n",
    "Next we conduct a hyper-parameter search over 100 configurations with 5-fold cross-validation on the training portion\n",
    "of the data. The best model is fitted on the training data and we report classification on the test data.\n",
    "\n",
    "Despite extensive parameter search, the best model achieves a test accuracy of 0.328, which is only marginally better\n",
    "than random guessing (0.2) as we have 5 treasure types to choose from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# extract target\n",
    "y_train = train_df[TARGET_FIELD]\n",
    "y_test = test_df[TARGET_FIELD]\n",
    "\n",
    "# remove target from features\n",
    "X_train = train_df.drop(TARGET_FIELD, axis=1)\n",
    "X_test = test_df.drop(TARGET_FIELD, axis=1)\n",
    "\n",
    "# preprocess categorical features\n",
    "cat_features = X_train.columns\n",
    "\n",
    "# replace all categorical nan values with \"n/a\" string\n",
    "X_train[cat_features] = X_train[cat_features].fillna(\"n/a\")\n",
    "X_test[cat_features] = X_test[cat_features].fillna(\"n/a\")\n",
    "\n",
    "# convert categorical features to strings and one-hot encode\n",
    "X_train[cat_features] = X_train[cat_features].astype(\"string\")\n",
    "X_test[cat_features] = X_test[cat_features].astype(\"string\")\n",
    "cat_steps = [(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    "\n",
    "preprocessor = Pipeline(steps=cat_steps)\n",
    "\n",
    "# fit and transform categorical features\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "display(f\"{X_train.shape=}\")\n",
    "\n",
    "# label-encode targets\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(pd.concat((y_train, y_test), axis=0))\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the parameter space for hyperparameter tuning\n",
    "param_dist = {\n",
    "    \"n_estimators\": [int(x) for x in np.linspace(start=200, stop=2000, num=10)],\n",
    "    \"max_features\": [\"log2\", \"sqrt\"],\n",
    "    \"max_depth\": [int(x) for x in np.linspace(10, 110, num=11)] + [None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "# create a base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# instantiate the randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=param_dist, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# get the best model and fit on full training data\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the best model\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
