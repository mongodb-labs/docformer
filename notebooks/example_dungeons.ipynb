{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train STORM model on Dungeons dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"door\": 2,\n",
      "  \"key_color\": \"red\",\n",
      "  \"corridor\": [\n",
      "    {\n",
      "      \"door_no\": 0,\n",
      "      \"red_key\": \"spellbooks\",\n",
      "      \"blue_key\": \"artifacts\",\n",
      "      \"green_key\": \"diamonds\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"dragon\"\n",
      "      ],\n",
      "      \"door_no\": 1,\n",
      "      \"red_key\": \"gold\",\n",
      "      \"blue_key\": \"diamonds\",\n",
      "      \"green_key\": \"diamonds\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"troll\"\n",
      "      ],\n",
      "      \"door_no\": 2,\n",
      "      \"red_key\": \"gold\",\n",
      "      \"blue_key\": \"artifacts\",\n",
      "      \"green_key\": \"gemstones\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"dragon\"\n",
      "      ],\n",
      "      \"door_no\": 3,\n",
      "      \"red_key\": \"artifacts\",\n",
      "      \"blue_key\": \"gold\",\n",
      "      \"green_key\": \"gemstones\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"wolf\"\n",
      "      ],\n",
      "      \"door_no\": 4,\n",
      "      \"red_key\": \"artifacts\",\n",
      "      \"blue_key\": \"spellbooks\",\n",
      "      \"green_key\": \"artifacts\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"troll\",\n",
      "        \"wolf\"\n",
      "      ],\n",
      "      \"door_no\": 5,\n",
      "      \"red_key\": \"diamonds\",\n",
      "      \"blue_key\": \"gold\",\n",
      "      \"green_key\": \"diamonds\"\n",
      "    },\n",
      "    {\n",
      "      \"monsters\": [\n",
      "        \"dragon\",\n",
      "        \"troll\"\n",
      "      ],\n",
      "      \"door_no\": 6,\n",
      "      \"red_key\": \"gemstones\",\n",
      "      \"blue_key\": \"gold\",\n",
      "      \"green_key\": \"gemstones\"\n",
      "    }\n",
      "  ],\n",
      "  \"treasure\": \"gold\"\n",
      "}\n",
      "len train: 8000, len test: 2000\n",
      "vocab size 53\n",
      "block size 148\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from storm_ml.datasets.dungeons import generate_data\n",
    "from storm_ml.preprocessing import (\n",
    "    DocTokenizerPipe,\n",
    "    PadTruncTokensPipe,\n",
    "    SchemaParserPipe,\n",
    "    TargetFieldPipe,\n",
    "    TokenEncoderPipe,\n",
    "    docs_to_df,\n",
    ")\n",
    "\n",
    "# generate Dungeons dataset (see storm_ml/datasets/dungeons.py)\n",
    "data = generate_data(\n",
    "    num_instances=10_000,\n",
    "    num_doors_range=(5, 10),\n",
    "    num_colors=3,\n",
    "    with_monsters=True,\n",
    "    num_treasures=5,\n",
    ")\n",
    "\n",
    "# print example dictionary\n",
    "print(json.dumps(data[0], indent=2))\n",
    "\n",
    "# load data into dataframe and split into train/test\n",
    "df = docs_to_df(data)\n",
    "train_docs_df, test_docs_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "TARGET_FIELD = \"treasure\"\n",
    "\n",
    "# create train and test pipelines\n",
    "pipes = {\n",
    "    \"schema\": SchemaParserPipe(),\n",
    "    \"target\": TargetFieldPipe(TARGET_FIELD),\n",
    "    \"tokenizer\": DocTokenizerPipe(path_in_field_tokens=True),\n",
    "    \"padding\": PadTruncTokensPipe(length=\"max\"),\n",
    "    \"encoder\": TokenEncoderPipe(),\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([(name, pipes[name]) for name in (\"schema\", \"target\", \"tokenizer\", \"padding\", \"encoder\")])\n",
    "\n",
    "# process train, eval and test data\n",
    "train_df = pipeline.fit_transform(train_docs_df)\n",
    "test_df = pipeline.transform(test_docs_df)\n",
    "\n",
    "# get stateful objects\n",
    "schema = pipes[\"schema\"].schema\n",
    "encoder = pipes[\"encoder\"].encoder\n",
    "block_size = pipes[\"padding\"].length\n",
    "\n",
    "# print data stats\n",
    "print(f\"len train: {len(train_df)}, len test: {len(test_df)}\")\n",
    "print(f\"vocab size {encoder.vocab_size}\")\n",
    "print(f\"block size {block_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device mps\n",
      "number of parameters: 0.81M\n"
     ]
    }
   ],
   "source": [
    "# create datasets, VPDA and model\n",
    "\n",
    "from storm_ml.model import STORM\n",
    "from storm_ml.model.vpda import DocumentVPDA\n",
    "from storm_ml.preprocessing import DFDataset\n",
    "from storm_ml.utils import ModelConfig, TrainConfig\n",
    "\n",
    "# model and train configs\n",
    "model_config = ModelConfig.from_preset(\"gpt-micro\")\n",
    "model_config.position_encoding = \"NONE\"\n",
    "model_config.vocab_size = encoder.vocab_size\n",
    "model_config.block_size = block_size\n",
    "\n",
    "train_config = TrainConfig()\n",
    "train_config.learning_rate = 1e-3\n",
    "train_config.n_warmup_batches = 1000\n",
    "\n",
    "# datasets\n",
    "train_dataset = DFDataset(train_df)\n",
    "test_dataset = DFDataset(test_df)\n",
    "\n",
    "vpda = DocumentVPDA(encoder, schema)\n",
    "model = STORM(model_config, train_config, vpda=vpda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  step: 0  |  epoch: 0  |  batch_num: 0  |  batch_dt: 0.00  |  batch_loss: 2.6633  |  test_loss: 2.6673  |  test_acc: 0.0300  |  lr: 1.01e-06  |\n",
      "|  step: 1  |  epoch: 1  |  batch_num: 100  |  batch_dt: 70.73  |  batch_loss: 1.2316  |  test_loss: 1.2135  |  test_acc: 0.1800  |  lr: 1.01e-04  |\n",
      "|  step: 2  |  epoch: 2  |  batch_num: 200  |  batch_dt: 73.97  |  batch_loss: 0.7978  |  test_loss: 0.7518  |  test_acc: 0.1600  |  lr: 2.01e-04  |\n",
      "|  step: 3  |  epoch: 3  |  batch_num: 300  |  batch_dt: 75.49  |  batch_loss: 0.6736  |  test_loss: 0.6504  |  test_acc: 0.2200  |  lr: 3.01e-04  |\n",
      "|  step: 4  |  epoch: 5  |  batch_num: 400  |  batch_dt: 76.41  |  batch_loss: 0.6348  |  test_loss: 0.6253  |  test_acc: 0.2000  |  lr: 4.01e-04  |\n",
      "|  step: 5  |  epoch: 6  |  batch_num: 500  |  batch_dt: 77.66  |  batch_loss: 0.6225  |  test_loss: 0.6184  |  test_acc: 0.1600  |  lr: 5.01e-04  |\n",
      "|  step: 6  |  epoch: 7  |  batch_num: 600  |  batch_dt: 79.02  |  batch_loss: 0.6276  |  test_loss: 0.6186  |  test_acc: 0.2600  |  lr: 6.01e-04  |\n",
      "|  step: 7  |  epoch: 8  |  batch_num: 700  |  batch_dt: 78.53  |  batch_loss: 0.6185  |  test_loss: 0.6182  |  test_acc: 0.2200  |  lr: 7.01e-04  |\n",
      "|  step: 8  |  epoch: 10  |  batch_num: 800  |  batch_dt: 74.20  |  batch_loss: 0.6173  |  test_loss: 0.6181  |  test_acc: 0.1300  |  lr: 8.01e-04  |\n",
      "|  step: 9  |  epoch: 11  |  batch_num: 900  |  batch_dt: 77.43  |  batch_loss: 0.6168  |  test_loss: 0.6179  |  test_acc: 0.1600  |  lr: 9.01e-04  |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/code/storm/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  step: 10  |  epoch: 12  |  batch_num: 1000  |  batch_dt: 79.27  |  batch_loss: 0.6186  |  test_loss: 0.6175  |  test_acc: 0.2200  |  lr: 1.00e-03  |\n",
      "|  step: 11  |  epoch: 13  |  batch_num: 1100  |  batch_dt: 80.86  |  batch_loss: 0.6177  |  test_loss: 0.6173  |  test_acc: 0.1900  |  lr: 9.83e-04  |\n",
      "|  step: 12  |  epoch: 15  |  batch_num: 1200  |  batch_dt: 83.06  |  batch_loss: 0.6166  |  test_loss: 0.6162  |  test_acc: 0.2600  |  lr: 9.67e-04  |\n",
      "|  step: 13  |  epoch: 16  |  batch_num: 1300  |  batch_dt: 77.07  |  batch_loss: 0.6172  |  test_loss: 0.6177  |  test_acc: 0.2900  |  lr: 9.50e-04  |\n",
      "|  step: 14  |  epoch: 17  |  batch_num: 1400  |  batch_dt: 83.70  |  batch_loss: 0.6159  |  test_loss: 0.6153  |  test_acc: 0.2500  |  lr: 9.34e-04  |\n",
      "|  step: 15  |  epoch: 18  |  batch_num: 1500  |  batch_dt: 84.99  |  batch_loss: 0.6140  |  test_loss: 0.6174  |  test_acc: 0.2800  |  lr: 9.17e-04  |\n",
      "|  step: 16  |  epoch: 20  |  batch_num: 1600  |  batch_dt: 80.91  |  batch_loss: 0.6163  |  test_loss: 0.6161  |  test_acc: 0.3800  |  lr: 9.01e-04  |\n",
      "|  step: 17  |  epoch: 21  |  batch_num: 1700  |  batch_dt: 81.47  |  batch_loss: 0.6156  |  test_loss: 0.6152  |  test_acc: 0.2400  |  lr: 8.84e-04  |\n",
      "|  step: 18  |  epoch: 22  |  batch_num: 1800  |  batch_dt: 80.38  |  batch_loss: 0.6152  |  test_loss: 0.6178  |  test_acc: 0.2700  |  lr: 8.68e-04  |\n",
      "|  step: 19  |  epoch: 23  |  batch_num: 1900  |  batch_dt: 79.22  |  batch_loss: 0.6160  |  test_loss: 0.6145  |  test_acc: 0.2700  |  lr: 8.51e-04  |\n",
      "|  step: 20  |  epoch: 25  |  batch_num: 2000  |  batch_dt: 81.47  |  batch_loss: 0.6189  |  test_loss: 0.6143  |  test_acc: 0.2400  |  lr: 8.35e-04  |\n",
      "|  step: 21  |  epoch: 26  |  batch_num: 2100  |  batch_dt: 80.40  |  batch_loss: 0.6160  |  test_loss: 0.6139  |  test_acc: 0.2800  |  lr: 8.18e-04  |\n",
      "|  step: 22  |  epoch: 27  |  batch_num: 2200  |  batch_dt: 78.72  |  batch_loss: 0.6149  |  test_loss: 0.6168  |  test_acc: 0.3400  |  lr: 8.02e-04  |\n",
      "|  step: 23  |  epoch: 28  |  batch_num: 2300  |  batch_dt: 79.25  |  batch_loss: 0.6161  |  test_loss: 0.6156  |  test_acc: 0.2400  |  lr: 7.85e-04  |\n",
      "|  step: 24  |  epoch: 30  |  batch_num: 2400  |  batch_dt: 80.72  |  batch_loss: 0.6159  |  test_loss: 0.6151  |  test_acc: 0.2200  |  lr: 7.69e-04  |\n",
      "|  step: 25  |  epoch: 31  |  batch_num: 2500  |  batch_dt: 77.34  |  batch_loss: 0.6171  |  test_loss: 0.6169  |  test_acc: 0.3200  |  lr: 7.52e-04  |\n",
      "|  step: 26  |  epoch: 32  |  batch_num: 2600  |  batch_dt: 80.48  |  batch_loss: 0.6151  |  test_loss: 0.6149  |  test_acc: 0.3400  |  lr: 7.36e-04  |\n",
      "|  step: 27  |  epoch: 33  |  batch_num: 2700  |  batch_dt: 75.78  |  batch_loss: 0.6163  |  test_loss: 0.6129  |  test_acc: 0.3600  |  lr: 7.19e-04  |\n",
      "|  step: 28  |  epoch: 35  |  batch_num: 2800  |  batch_dt: 80.70  |  batch_loss: 0.6135  |  test_loss: 0.6147  |  test_acc: 0.3100  |  lr: 7.03e-04  |\n",
      "|  step: 29  |  epoch: 36  |  batch_num: 2900  |  batch_dt: 80.84  |  batch_loss: 0.6119  |  test_loss: 0.6128  |  test_acc: 0.6200  |  lr: 6.86e-04  |\n",
      "|  step: 30  |  epoch: 37  |  batch_num: 3000  |  batch_dt: 81.77  |  batch_loss: 0.6105  |  test_loss: 0.6103  |  test_acc: 0.6300  |  lr: 6.70e-04  |\n",
      "|  step: 31  |  epoch: 38  |  batch_num: 3100  |  batch_dt: 73.33  |  batch_loss: 0.6106  |  test_loss: 0.6080  |  test_acc: 0.6800  |  lr: 6.53e-04  |\n",
      "|  step: 32  |  epoch: 40  |  batch_num: 3200  |  batch_dt: 81.30  |  batch_loss: 0.6072  |  test_loss: 0.6067  |  test_acc: 0.7300  |  lr: 6.37e-04  |\n",
      "|  step: 33  |  epoch: 41  |  batch_num: 3300  |  batch_dt: 80.50  |  batch_loss: 0.6062  |  test_loss: 0.6098  |  test_acc: 0.8000  |  lr: 6.20e-04  |\n",
      "|  step: 34  |  epoch: 42  |  batch_num: 3400  |  batch_dt: 78.79  |  batch_loss: 0.6057  |  test_loss: 0.6062  |  test_acc: 0.7700  |  lr: 6.04e-04  |\n",
      "|  step: 35  |  epoch: 43  |  batch_num: 3500  |  batch_dt: 73.61  |  batch_loss: 0.6055  |  test_loss: 0.6057  |  test_acc: 0.8300  |  lr: 5.87e-04  |\n",
      "|  step: 36  |  epoch: 45  |  batch_num: 3600  |  batch_dt: 76.82  |  batch_loss: 0.6074  |  test_loss: 0.6036  |  test_acc: 0.8500  |  lr: 5.71e-04  |\n",
      "|  step: 37  |  epoch: 46  |  batch_num: 3700  |  batch_dt: 78.85  |  batch_loss: 0.6054  |  test_loss: 0.6030  |  test_acc: 0.8900  |  lr: 5.54e-04  |\n",
      "|  step: 38  |  epoch: 47  |  batch_num: 3800  |  batch_dt: 79.34  |  batch_loss: 0.6040  |  test_loss: 0.6032  |  test_acc: 0.9300  |  lr: 5.38e-04  |\n",
      "|  step: 39  |  epoch: 48  |  batch_num: 3900  |  batch_dt: 75.80  |  batch_loss: 0.6027  |  test_loss: 0.6013  |  test_acc: 0.9900  |  lr: 5.21e-04  |\n",
      "|  step: 40  |  epoch: 50  |  batch_num: 4000  |  batch_dt: 77.03  |  batch_loss: 0.6013  |  test_loss: 0.6030  |  test_acc: 0.9800  |  lr: 5.05e-04  |\n",
      "|  step: 41  |  epoch: 51  |  batch_num: 4100  |  batch_dt: 79.69  |  batch_loss: 0.5999  |  test_loss: 0.6037  |  test_acc: 0.9700  |  lr: 4.88e-04  |\n",
      "|  step: 42  |  epoch: 52  |  batch_num: 4200  |  batch_dt: 82.38  |  batch_loss: 0.6010  |  test_loss: 0.6012  |  test_acc: 0.9300  |  lr: 4.72e-04  |\n",
      "|  step: 43  |  epoch: 53  |  batch_num: 4300  |  batch_dt: 81.65  |  batch_loss: 0.5995  |  test_loss: 0.6026  |  test_acc: 0.9200  |  lr: 4.55e-04  |\n",
      "|  step: 44  |  epoch: 55  |  batch_num: 4400  |  batch_dt: 81.96  |  batch_loss: 0.5995  |  test_loss: 0.6032  |  test_acc: 0.9600  |  lr: 4.39e-04  |\n",
      "|  step: 45  |  epoch: 56  |  batch_num: 4500  |  batch_dt: 85.10  |  batch_loss: 0.6018  |  test_loss: 0.6020  |  test_acc: 0.9500  |  lr: 4.22e-04  |\n",
      "|  step: 46  |  epoch: 57  |  batch_num: 4600  |  batch_dt: 83.46  |  batch_loss: 0.5995  |  test_loss: 0.5985  |  test_acc: 0.9900  |  lr: 4.06e-04  |\n",
      "|  step: 47  |  epoch: 58  |  batch_num: 4700  |  batch_dt: 81.07  |  batch_loss: 0.5991  |  test_loss: 0.6010  |  test_acc: 0.9900  |  lr: 3.89e-04  |\n",
      "|  step: 48  |  epoch: 60  |  batch_num: 4800  |  batch_dt: 75.20  |  batch_loss: 0.5985  |  test_loss: 0.6043  |  test_acc: 1.0000  |  lr: 3.73e-04  |\n",
      "|  step: 49  |  epoch: 61  |  batch_num: 4900  |  batch_dt: 81.35  |  batch_loss: 0.5990  |  test_loss: 0.6037  |  test_acc: 0.9600  |  lr: 3.56e-04  |\n"
     ]
    }
   ],
   "source": [
    "from storm_ml.inference import Predictor\n",
    "from storm_ml.utils.guild import print_guild_scalars\n",
    "\n",
    "# create a predictor\n",
    "predictor = Predictor(model, encoder, TARGET_FIELD)\n",
    "\n",
    "\n",
    "# model callback during training, prints training and test metrics\n",
    "def progress_callback(model):\n",
    "    if model.batch_num % train_config.eval_every == 0:\n",
    "        print_guild_scalars(\n",
    "            step=f\"{int(model.batch_num / train_config.eval_every)}\",\n",
    "            epoch=model.epoch_num,\n",
    "            batch_num=model.batch_num,\n",
    "            batch_dt=f\"{model.batch_dt*1000:.2f}\",\n",
    "            batch_loss=f\"{model.loss:.4f}\",\n",
    "            test_loss=f\"{predictor.ce_loss(test_dataset.sample(n=100)):.4f}\",\n",
    "            test_acc=f\"{predictor.accuracy(test_dataset.sample(n=100)):.4f}\",\n",
    "            lr=f\"{model.learning_rate:.2e}\",\n",
    "        )\n",
    "\n",
    "\n",
    "model.set_callback(\"on_batch_end\", progress_callback)\n",
    "model.train_model(train_dataset, batches=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242a5f3fac1a4eb5a62f3818c85c66f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9810\n",
      "Model predictions:  ['gold', 'artifacts', 'diamonds', 'artifacts', 'diamonds', 'diamonds', 'artifacts', 'gemstones', 'artifacts', 'gemstones']\n",
      "Correct labels:  ['gold', 'artifacts', 'diamonds', 'artifacts', 'diamonds', 'diamonds', 'artifacts', 'gemstones', 'artifacts', 'gemstones']\n"
     ]
    }
   ],
   "source": [
    "acc = predictor.accuracy(test_dataset, show_progress=True)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "# we can also access the predictions with the `predict()` method\n",
    "predictions = predictor.predict(test_dataset)\n",
    "print(\"Model predictions: \", predictions[:10])\n",
    "print(\"Correct labels: \", test_dataset.df[\"target\"].to_list()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
